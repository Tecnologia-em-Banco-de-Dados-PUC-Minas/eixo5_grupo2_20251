{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdtPFREVPSrB"
      },
      "source": [
        "# 1. Carregamento das bibliotecas ðŸ“¦"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyGithub\n",
        "!pip install Unidecode\n",
        "!python -m spacy download pt_core_news_sm\n",
        "import pandas as pd\n",
        "import re\n",
        "import unidecode\n",
        "import spacy\n",
        "import getpass\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from github import Github\n",
        "import base64"
      ],
      "metadata": {
        "id": "8yJuxha-HbTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. CÃ³digo Machine Learning âš™ï¸"
      ],
      "metadata": {
        "id": "MYR0_29URe-M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMHZq9tsO6vm"
      },
      "outputs": [],
      "source": [
        "# Carragamento dos dados\n",
        "github_csv_url = \"https://raw.githubusercontent.com/Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251/main/projeto/development/silver/order_reviews_tratados.csv\"\n",
        "df = pd.read_csv(github_csv_url)\n",
        "\n",
        "# PrÃ©-processamento do texto\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = str(text).lower()\n",
        "    text = unidecode.unidecode(text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    doc = nlp(text)\n",
        "    stop_words = {\n",
        "        'o', 'a', 'os', 'as', 'de', 'do', 'da', 'em', 'por', 'para', 'com',\n",
        "        'Ã©', 'estÃ¡', 'etc', 'que', 'e', 'no', 'na', 'um', 'uma', 'foi',\n",
        "        'tÃ¡', 'tava', 'pra', 'mas', 'como', 'se', 'tem', 'jÃ¡', 'bem',\n",
        "        'muito', 'vai', 'ser'\n",
        "    }\n",
        "    tokens = [token.lemma_ for token in doc if token.lemma_ not in stop_words and len(token.lemma_) > 2]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# 3. ClassificaÃ§Ã£o dos sentimentos\n",
        "def classify_sentiment(score):\n",
        "    if score >= 4:\n",
        "        return 'positivo'\n",
        "    elif score == 3:\n",
        "        return 'neutro'\n",
        "    else:\n",
        "        return 'negativo'\n",
        "\n",
        "df['review_comment_title'] = df['review_comment_title'].fillna('')\n",
        "df['review_comment_message'] = df['review_comment_message'].fillna('')\n",
        "df['combined_text'] = df['review_comment_title'] + ' ' + df['review_comment_message']\n",
        "df['sentiment'] = df['review_score'].apply(classify_sentiment)\n",
        "\n",
        "# SeparaÃ§Ã£o entre treino e teste\n",
        "X = df['combined_text']\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Pipeline de processamento e classificaÃ§Ã£o\n",
        "pipeline = make_imb_pipeline(\n",
        "    TfidfVectorizer(\n",
        "        preprocessor=preprocess_text,\n",
        "        ngram_range=(1, 3),\n",
        "        max_features=8000,\n",
        "        min_df=5\n",
        "    ),\n",
        "    SMOTE(sampling_strategy='not majority', random_state=42),\n",
        "    LinearSVC(class_weight='balanced', C=1.0, max_iter=10000, random_state=42)\n",
        ")\n",
        "\n",
        "# Treinamento do modelo\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. AvaliaÃ§Ã£o do modelo\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"\\nRelatÃ³rio de ClassificaÃ§Ã£o:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nMatriz de ConfusÃ£o:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# PrevisÃµes finais e exportaÃ§Ã£o\n",
        "df['predicted_sentiment'] = pipeline.predict(df['combined_text'])\n",
        "output_file = \"order_reviews_com_sentimento.csv\"\n",
        "df.to_csv(output_file, index=False, encoding='utf-8')\n",
        "print(f\"\\n Arquivo exportado como {output_file}\")\n",
        "\n",
        "# FunÃ§Ã£o de previsÃ£o manual\n",
        "def predict_sentiment(text):\n",
        "    return pipeline.predict([text])[0]\n",
        "\n",
        "print(\"\\nTestes manuais:\")\n",
        "print(\"-> Produto excelente, recomendo!:\", predict_sentiment(\"Produto excelente, recomendo!\"))\n",
        "print(\"-> A entrega atrasou mas o produto Ã© bom:\", predict_sentiment(\"A entrega atrasou mas o produto Ã© bom\"))\n",
        "print(\"-> Muito ruim, veio quebrado:\", predict_sentiment(\"Muito ruim, veio quebrado\"))\n",
        "\n",
        "# 10. Upload para GitHub\n",
        "print(\"\\nðŸ”’ AutenticaÃ§Ã£o no GitHub\")\n",
        "token = getpass.getpass(\"Digite seu token de acesso do GitHub (ele nÃ£o serÃ¡ exibido): \")\n",
        "repo_name = \"Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251\"\n",
        "remote_path = \"projeto/development/gold/order_reviews_com_sentimento.csv\"\n",
        "commit_message = \"Adiciona arquivo com sentimentos previstos\"\n",
        "\n",
        "# Conectar ao GitHub e enviar o arquivo\n",
        "try:\n",
        "    g = Github(token)\n",
        "    repo = g.get_repo(repo_name)\n",
        "\n",
        "    with open(output_file, \"rb\") as file:\n",
        "        content = file.read()\n",
        "        content_b64 = base64.b64encode(content).decode(\"utf-8\")\n",
        "\n",
        "    try:\n",
        "        existing_file = repo.get_contents(remote_path)\n",
        "        repo.update_file(remote_path, commit_message, content, existing_file.sha)\n",
        "        print(\" Arquivo atualizado no GitHub com sucesso!\")\n",
        "    except:\n",
        "        repo.create_file(remote_path, commit_message, content, branch=\"main\")\n",
        "        print(\" Arquivo criado no GitHub com sucesso!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Erro ao enviar para o GitHub: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}