{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkp2H8_9Tmjw"
      },
      "source": [
        "**BIBLIOTECAS** 📚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXKkI_vvCX3z",
        "outputId": "6cc39cf6-8c6f-4da5-d2bb-7eec774440ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyGithub\n",
            "  Downloading PyGithub-2.6.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (2.32.3)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (4.13.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (2.3.0)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.11/dist-packages (from PyGithub) (1.2.18)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pynacl>=1.4.0->PyGithub) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (2025.1.31)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->PyGithub) (1.17.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.22)\n",
            "Downloading PyGithub-2.6.1-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynacl, PyGithub\n",
            "Successfully installed PyGithub-2.6.1 pynacl-1.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install PyGithub\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from io import StringIO\n",
        "from github import Github\n",
        "from getpass import getpass\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpWIw5hSxV5l"
      },
      "source": [
        "***TABELA REVIEWS***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "TGrWzXSjw75J",
        "outputId": "65f97c5e-d726-4ff3-e984-9c2cba23a86a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Colunas identificadas no arquivo:\n",
            "['review_id', 'order_id', 'review_score', 'review_comment_title', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp']\n",
            "\n",
            "Data convertida (DD/MM/AAAA):\n",
            "0    18/01/2018\n",
            "1    10/03/2018\n",
            "2    17/02/2018\n",
            "3    21/04/2017\n",
            "4    01/03/2018\n",
            "Name: review_creation_date, dtype: object\n",
            "\n",
            "Coluna 'review_answer_timestamp' removida com sucesso!\n",
            "\n",
            "Processo concluído com sucesso!\n",
            "Dados finais disponíveis em: order_reviews_tratados.csv\n",
            "Colunas finais: ['review_id', 'order_id', 'review_score', 'review_comment_title', 'review_comment_message', 'review_creation_date']\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2b266dde086a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-2b266dde086a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mGITHUB_TOKEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔑 Digite seu token do GitHub e pressione Enter: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGithub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGITHUB_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             )\n\u001b[0;32m-> 1159\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "def remove_acentos_e_especiais(texto):\n",
        "    \"\"\"Remove acentos e caracteres especiais do texto\"\"\"\n",
        "    if pd.isna(texto):\n",
        "        return texto\n",
        "    texto = unicodedata.normalize('NFKD', str(texto)).encode('ASCII', 'ignore').decode('ASCII')\n",
        "    return ''.join(c for c in texto if c.isalnum() or c.isspace())\n",
        "\n",
        "def conver_data(data_str):\n",
        "    \"\"\"Converte data no formato AAAAMMDD para DD/MM/AAAA\"\"\"\n",
        "    try:\n",
        "        return datetime.strptime(data_str, '%Y%m%d').strftime('%d/%m/%Y')\n",
        "    except:\n",
        "        return data_str\n",
        "\n",
        "def main():\n",
        "    github_url = \"https://raw.githubusercontent.com/Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251/main/projeto/development/bronze/olist_order_reviews_dataset.csv\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(github_url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        df = pd.read_csv(StringIO(response.text))\n",
        "\n",
        "        print(\"\\nColunas identificadas no arquivo:\")\n",
        "        print(df.columns.tolist())\n",
        "\n",
        "        for coluna in df.columns:\n",
        "            if df[coluna].dtype == 'object':\n",
        "                df[coluna] = df[coluna].apply(remove_acentos_e_especiais)\n",
        "                df[coluna] = df[coluna].str.upper().str.strip()\n",
        "                df[coluna] = df[coluna].str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "        if 'review_creation_date' in df.columns:\n",
        "            df['review_creation_date'] = df['review_creation_date'].astype(str).str.split().str[0]\n",
        "            df['review_creation_date'] = df['review_creation_date'].apply(conver_data)\n",
        "            print(\"\\nData convertida (DD/MM/AAAA):\")\n",
        "            print(df['review_creation_date'].head())\n",
        "\n",
        "        if 'review_answer_timestamp' in df.columns:\n",
        "            df.drop('review_answer_timestamp', axis=1, inplace=True)\n",
        "            print(\"\\nColuna 'review_answer_timestamp' removida com sucesso!\")\n",
        "\n",
        "        df = df.dropna().drop_duplicates()\n",
        "\n",
        "        output_filename = 'order_reviews_tratados.csv'\n",
        "        df.to_csv(output_filename, index=False, encoding='utf-8')\n",
        "\n",
        "        print(\"\\nProcesso concluído com sucesso!\")\n",
        "        print(\"Dados finais disponíveis em:\", output_filename)\n",
        "        print(\"Colunas finais:\", df.columns.tolist())\n",
        "\n",
        "        try:\n",
        "            GITHUB_TOKEN = getpass(\"🔑 Digite seu token do GitHub e pressione Enter: \")\n",
        "            g = Github(GITHUB_TOKEN)\n",
        "\n",
        "            repo_name = \"Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251\"\n",
        "            repo = g.get_repo(repo_name)\n",
        "\n",
        "            github_file_path = \"projeto/development/silver/order_reviews_tratados.csv\"\n",
        "\n",
        "            with open(output_filename, \"r\") as file:\n",
        "                content = file.read()\n",
        "\n",
        "            try:\n",
        "                contents = repo.get_contents(github_file_path)\n",
        "                repo.update_file(\n",
        "                    path=github_file_path,\n",
        "                    message=\"Atualização automática via Colab\",\n",
        "                    content=content,\n",
        "                    sha=contents.sha,\n",
        "                    branch=\"main\"\n",
        "                )\n",
        "                print(\"Arquivo atualizado no GitHub!\")\n",
        "            except Exception as e:\n",
        "                if \"404\" in str(e):\n",
        "                    repo.create_file(\n",
        "                        path=github_file_path,\n",
        "                        message=\"Upload via Colab\",\n",
        "                        content=content,\n",
        "                        branch=\"main\"\n",
        "                    )\n",
        "                    print(\"☁️ Arquivo criado no GitHub!\")\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nErro ao enviar para o GitHub: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nErro ao processar o arquivo: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGtWZ8Jyx_c6"
      },
      "source": [
        "***TABELA ORDER_ITEMS_ID***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RHs7uTxzkk7"
      },
      "outputs": [],
      "source": [
        "def remove_acentos_e_especiais(texto):\n",
        "    \"\"\"Remove acentos e caracteres especiais do texto\"\"\"\n",
        "    if pd.isna(texto):\n",
        "        return texto\n",
        "    texto = str(texto)\n",
        "    texto = unicodedata.normalize('NFD', texto)\n",
        "    texto = texto.encode('ascii', 'ignore').decode('utf-8')\n",
        "    return texto\n",
        "\n",
        "def main():\n",
        "\n",
        "    github_url = \"https://raw.githubusercontent.com/Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251/main/projeto/development/bronze/olist_order_items_dataset.csv\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(github_url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        df = pd.read_csv(StringIO(response.text))\n",
        "\n",
        "        print(\"\\nColunas identificadas no arquivo:\")\n",
        "        print(df.columns.tolist())\n",
        "\n",
        "        for coluna in df.columns:\n",
        "            if df[coluna].dtype == 'object':\n",
        "                df[coluna] = df[coluna].apply(remove_acentos_e_especiais)\n",
        "                df[coluna] = df[coluna].str.upper().str.strip()\n",
        "                df[coluna] = df[coluna].str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "        if 'shipping_limit_date' in df.columns:\n",
        "            df.drop('shipping_limit_date', axis=1, inplace=True)\n",
        "            print(\"\\nColuna 'shipping_limit_date' removida com sucesso!\")\n",
        "\n",
        "        df = df.dropna().drop_duplicates()\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        output_filename = f'order_items_tratados_{timestamp}.csv'\n",
        "        df.to_csv(output_filename, index=False, encoding='utf-8')\n",
        "\n",
        "        print(\"\\nProcesso concluído com sucesso!\")\n",
        "        print(\"Dados finais disponíveis em:\", output_filename)\n",
        "        print(\"Colunas finais:\", df.columns.tolist())\n",
        "\n",
        "        try:\n",
        "            GITHUB_TOKEN = getpass(\"🔑 Digite seu token do GitHub e pressione Enter: \")\n",
        "            g = Github(GITHUB_TOKEN)\n",
        "\n",
        "            repo_name = \"Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251\"\n",
        "            repo = g.get_repo(repo_name)\n",
        "\n",
        "            github_file_path = f\"projeto/development/silver/order_items_tratados.csv\"\n",
        "\n",
        "            with open(output_filename, \"r\") as file:\n",
        "                content = file.read()\n",
        "\n",
        "            repo.create_file(\n",
        "                path=github_file_path,\n",
        "                message=f\"Atualização automática via Colab\",\n",
        "                content=content,\n",
        "                branch=\"main\"\n",
        "            )\n",
        "            print(\"☁️ Arquivo criado no GitHub!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nErro ao enviar para o GitHub: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nErro ao processar o arquivo: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83jhig--D0hb"
      },
      "source": [
        "***TABELA ORDER_PAYMENTS***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyhpL1NbCwP6"
      },
      "outputs": [],
      "source": [
        "def remove_acentos_e_especiais(texto):\n",
        "    \"\"\"Remove acentos e caracteres especiais do texto\"\"\"\n",
        "    if pd.isna(texto):\n",
        "        return texto\n",
        "    texto = unicodedata.normalize('NFKD', str(texto)).encode('ASCII', 'ignore').decode('ASCII')\n",
        "    return ''.join(c for c in texto if c.isalnum() or c.isspace())\n",
        "\n",
        "def main():\n",
        "    github_url = \"https://raw.githubusercontent.com/Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251/main/projeto/development/bronze/olist_order_payments_dataset.csv\"\n",
        "    response = requests.get(github_url)\n",
        "    response.raise_for_status()\n",
        "    df = pd.read_csv(StringIO(response.text))\n",
        "\n",
        "    for coluna in df.columns:\n",
        "        if df[coluna].dtype == 'object':\n",
        "            df[coluna] = df[coluna].apply(remove_acentos_e_especiais)\n",
        "            df[coluna] = df[coluna].str.upper().str.strip()\n",
        "            df[coluna] = df[coluna].str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "    if 'payment_sequential' in df.columns:\n",
        "        df.drop('payment_sequential', axis=1, inplace=True)\n",
        "\n",
        "    df = df.dropna().drop_duplicates()\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_filename = f\"order_payments_tratados_{timestamp}.csv\"\n",
        "    df.to_csv(output_filename, index=False)\n",
        "\n",
        "    print(\"\\nProcesso concluído com sucesso!\")\n",
        "    print(\"Dados finais disponíveis em:\", output_filename)\n",
        "    print(\"Colunas finais:\", df.columns.tolist())\n",
        "\n",
        "    try:\n",
        "        GITHUB_TOKEN = getpass(\"🔑 Digite seu token do GitHub e pressione Enter: \")\n",
        "        g = Github(GITHUB_TOKEN)\n",
        "\n",
        "        repo_name = \"Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251\"\n",
        "        repo = g.get_repo(repo_name)\n",
        "\n",
        "        github_file_path = \"projeto/development/silver/order_payments_tratados.csv\"\n",
        "\n",
        "        with open(output_filename, \"r\") as file:\n",
        "            content = file.read()\n",
        "\n",
        "        repo.create_file(\n",
        "            path=github_file_path,\n",
        "            message=f\"Atualização automática via Colab\",\n",
        "            content=content,\n",
        "            branch=\"main\"\n",
        "        )\n",
        "        print(\"☁️ Arquivo criado no GitHub!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nErro ao enviar para o GitHub: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE90FeE-EV0V"
      },
      "source": [
        "***TABELA ORDER_PRODUCTS***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "hC2zdgsKEWSE",
        "outputId": "fdcd3042-845b-41ab-ff77-50c866b8c94a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'requests' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f8e120285570>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-f8e120285570>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mgithub_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251/main/projeto/development/bronze/olist_products_dataset.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgithub_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
          ]
        }
      ],
      "source": [
        "def remove_acentos_e_especiais(texto):\n",
        "    \"\"\"Remove acentos e caracteres especiais do texto\"\"\"\n",
        "    if pd.isna(texto):\n",
        "        return texto\n",
        "    texto = unicodedata.normalize('NFKD', str(texto)).encode('ASCII', 'ignore').decode('ASCII')\n",
        "    return ''.join(c for c in texto if c.isalnum() or c.isspace())\n",
        "\n",
        "def main():\n",
        "    github_url = \"https://raw.githubusercontent.com/Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251/main/projeto/development/bronze/olist_products_dataset.csv\"\n",
        "    response = requests.get(github_url)\n",
        "    response.raise_for_status()\n",
        "    df = pd.read_csv(StringIO(response.text))\n",
        "\n",
        "    print(\"\\nColunas identificadas no arquivo:\")\n",
        "    print(df.columns.tolist())\n",
        "\n",
        "    colunas_para_remover = [\n",
        "        \"product_name_lenght\",\n",
        "        \"product_description_lenght\",\n",
        "        \"product_photos_qty\",\n",
        "        \"product_weight_g\",\n",
        "        \"product_length_cm\",\n",
        "        \"product_height_cm\",\n",
        "        \"product_width_cm\"\n",
        "    ]\n",
        "\n",
        "    colunas_removidas = [col for col in colunas_para_remover if col in df.columns]\n",
        "    df.drop(columns=colunas_removidas, errors='ignore', inplace=True)\n",
        "\n",
        "    if colunas_removidas:\n",
        "        print(\"\\nColunas removidas com sucesso:\", colunas_removidas)\n",
        "    else:\n",
        "        print(\"\\nNenhuma das colunas especificadas foi encontrada no arquivo.\")\n",
        "\n",
        "    for coluna in df.columns:\n",
        "        if df[coluna].dtype == 'object':\n",
        "            df[coluna] = df[coluna].apply(remove_acentos_e_especiais)\n",
        "            df[coluna] = df[coluna].str.upper().str.strip()\n",
        "            df[coluna] = df[coluna].str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "    df = df.dropna().drop_duplicates()\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_filename = f'order_products_tratados_{timestamp}.csv'\n",
        "    df.to_csv(output_filename, index=False, encoding='utf-8')\n",
        "\n",
        "    print(\"\\nProcesso concluído com sucesso!\")\n",
        "    print(\"Dados finais disponíveis em:\", output_filename)\n",
        "    print(\"Colunas finais:\", df.columns.tolist())\n",
        "\n",
        "    try:\n",
        "        GITHUB_TOKEN = getpass.getpass(\"🔑 Digite seu token do GitHub e pressione Enter: \")\n",
        "        g = Github(GITHUB_TOKEN)\n",
        "\n",
        "        repo_name = \"Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251\"\n",
        "        repo = g.get_repo(repo_name)\n",
        "\n",
        "        github_file_path = \"projeto/development/silver/order_products_tratados.csv\"\n",
        "\n",
        "        try:\n",
        "            contents = repo.get_contents(github_file_path, ref=\"main\")\n",
        "            repo.update_file(\n",
        "                path=github_file_path,\n",
        "                message=f\"Atualização automática via Colab\",\n",
        "                content=df.to_csv(index=False, encoding='utf-8'),\n",
        "                sha=contents.sha,\n",
        "                branch=\"main\"\n",
        "            )\n",
        "            print(\"☁️ Arquivo atualizado no GitHub com sucesso!\")\n",
        "        except:\n",
        "            repo.create_file(\n",
        "                path=github_file_path,\n",
        "                message=f\"Criação automática ({timestamp})\",\n",
        "                content=df.to_csv(index=False, encoding='utf-8'),\n",
        "                branch=\"main\"\n",
        "            )\n",
        "            print(\"☁️ Arquivo criado no GitHub!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nErro ao enviar para o GitHub: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUNcQ9WjLqRb"
      },
      "source": [
        "***TABELA ORDER_SELLERS***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IJZgsZFLvfU"
      },
      "outputs": [],
      "source": [
        "def remove_acentos_e_especiais(texto):\n",
        "    \"\"\"Remove acentos e caracteres especiais do texto\"\"\"\n",
        "    if pd.isna(texto):\n",
        "        return texto\n",
        "    texto = unicodedata.normalize('NFKD', str(texto)).encode('ASCII', 'ignore').decode('ASCII')\n",
        "    return ''.join(c for c in texto if c.isalnum() or c.isspace())\n",
        "\n",
        "def main():\n",
        "    github_url = \"https://raw.githubusercontent.com/Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251/main/projeto/development/bronze/olist_sellers_dataset.csv\"\n",
        "    response = requests.get(github_url)\n",
        "    response.raise_for_status()\n",
        "    df = pd.read_csv(StringIO(response.text))\n",
        "\n",
        "    print(\"\\nColunas identificadas no arquivo:\")\n",
        "    print(df.columns.tolist())\n",
        "\n",
        "    if 'seller_zip_code_prefix' in df.columns:\n",
        "        df.drop('seller_zip_code_prefix', axis=1, inplace=True)\n",
        "        print(\"\\nColuna 'seller_zip_code_prefix' removida com sucesso!\")\n",
        "\n",
        "    colunas_para_remover = [\n",
        "    ]\n",
        "\n",
        "    colunas_removidas = [col for col in colunas_para_remover if col in df.columns]\n",
        "    df.drop(columns=colunas_removidas, errors='ignore', inplace=True)\n",
        "\n",
        "    if colunas_removidas:\n",
        "        print(\"\\nColunas removidas com sucesso:\", colunas_removidas)\n",
        "    else:\n",
        "        print(\"\\nNenhuma das colunas especificadas foi encontrada no arquivo.\")\n",
        "\n",
        "    for coluna in df.columns:\n",
        "        if df[coluna].dtype == 'object':\n",
        "            df[coluna] = df[coluna].apply(remove_acentos_e_especiais)\n",
        "            df[coluna] = df[coluna].str.upper().str.strip()\n",
        "            df[coluna] = df[coluna].str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "    df = df.dropna().drop_duplicates()\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_filename = f'order_sellers_tratados_{timestamp}.csv'\n",
        "    df.to_csv(output_filename, index=False, encoding='utf-8')\n",
        "\n",
        "    print(\"\\nProcesso concluído com sucesso!\")\n",
        "    print(\"Dados finais disponíveis em:\", output_filename)\n",
        "    print(\"Colunas finais:\", df.columns.tolist())\n",
        "\n",
        "    try:\n",
        "        GITHUB_TOKEN = getpass.getpass(\"🔑 Digite seu token do GitHub e pressione Enter: \")\n",
        "        g = Github(GITHUB_TOKEN)\n",
        "\n",
        "        repo_name = \"Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251\"\n",
        "        repo = g.get_repo(repo_name)\n",
        "\n",
        "        github_file_path = \"projeto/development/silver/order_sellers_tratados.csv\"\n",
        "\n",
        "        try:\n",
        "            contents = repo.get_contents(github_file_path, ref=\"main\")\n",
        "            repo.update_file(\n",
        "                path=github_file_path,\n",
        "                message=f\"Atualização automática via Colab\",\n",
        "                content=df.to_csv(index=False, encoding='utf-8'),\n",
        "                sha=contents.sha,\n",
        "                branch=\"main\"\n",
        "            )\n",
        "            print(\"☁️ Arquivo atualizado no GitHub com sucesso!\")\n",
        "        except:\n",
        "            repo.create_file(\n",
        "                path=github_file_path,\n",
        "                message=f\"Criação automática ({timestamp})\",\n",
        "                content=df.to_csv(index=False, encoding='utf-8'),\n",
        "                branch=\"main\"\n",
        "            )\n",
        "            print(\"☁️ Arquivo criado no GitHub!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nErro ao enviar para o GitHub: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoQAEJAbO0bd"
      },
      "source": [
        "***TABELA ORDERS***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV7Ei75QO43j"
      },
      "outputs": [],
      "source": [
        "def remove_acentos_e_especiais(texto):\n",
        "    \"\"\"Remove acentos e caracteres especiais do texto\"\"\"\n",
        "    if pd.isna(texto):\n",
        "        return texto\n",
        "    texto = str(texto)\n",
        "    texto = unicodedata.normalize('NFD', texto)\n",
        "    texto = texto.encode('ascii', 'ignore').decode('utf-8')\n",
        "    return texto\n",
        "\n",
        "def main():\n",
        "    github_url = \"https://raw.githubusercontent.com/Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251/main/projeto/development/bronze/olist_orders_dataset.csv\"\n",
        "    response = requests.get(github_url)\n",
        "    response.raise_for_status()\n",
        "    df = pd.read_csv(StringIO(response.text))\n",
        "\n",
        "    print(\"\\nColunas identificadas no arquivo:\")\n",
        "    print(df.columns.tolist())\n",
        "\n",
        "    for coluna in df.columns:\n",
        "        if df[coluna].dtype == 'object':\n",
        "            df[coluna] = df[coluna].apply(remove_acentos_e_especiais)\n",
        "            df[coluna] = df[coluna].str.upper().str.strip()\n",
        "            df[coluna] = df[coluna].str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "    colunas_data = [\n",
        "        \"order_purchase_timestamp\",\n",
        "        \"order_approved_at\",\n",
        "        \"order_delivered_carrier_date\",\n",
        "        \"order_delivered_customer_date\",\n",
        "        \"order_estimated_delivery_date\",\n",
        "    ]\n",
        "\n",
        "    for coluna in colunas_data:\n",
        "        if coluna in df.columns:\n",
        "            df[coluna] = df[coluna].str.split().str[0]  # Pega apenas a parte da data\n",
        "            df[coluna] = pd.to_datetime(df[coluna], errors='coerce').dt.strftime('%d/%m/%Y')\n",
        "            print(f\"✔ Coluna {coluna} formatada para DD/MM/AAAA\")\n",
        "\n",
        "    colunas_para_remover = [\n",
        "        \"product_name_lenght\",\n",
        "        \"product_description_lenght\",\n",
        "        \"product_photos_qty\",\n",
        "        \"product_weight_g\",\n",
        "        \"product_length_cm\",\n",
        "        \"product_height_cm\",\n",
        "        \"product_width_cm\"\n",
        "    ]\n",
        "\n",
        "    colunas_removidas = [col for col in colunas_para_remover if col in df.columns]\n",
        "    df.drop(columns=colunas_removidas, inplace=True, errors='ignore')\n",
        "\n",
        "    if colunas_removidas:\n",
        "        print(\"\\nColunas removidas:\", \", \".join(colunas_removidas))\n",
        "    else:\n",
        "        print(\"\\nNenhuma das colunas para remoção foi encontrada\")\n",
        "\n",
        "    df = df.dropna().drop_duplicates()\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_filename = f'orders_tratados_{timestamp}.csv'\n",
        "    df.to_csv(output_filename, index=False, encoding='utf-8')\n",
        "\n",
        "    print(\"\\nProcesso concluído com sucesso!\")\n",
        "    print(\"Dados finais disponíveis em:\", output_filename)\n",
        "    print(\"Colunas finais:\", df.columns.tolist())\n",
        "\n",
        "    try:\n",
        "        GITHUB_TOKEN = getpass.getpass(\"🔑 Digite seu token do GitHub e pressione Enter: \")\n",
        "        g = Github(GITHUB_TOKEN)\n",
        "\n",
        "        repo_name = \"Tecnologia-em-Banco-de-Dados-PUC-Minas/eixo5_grupo2_20251\"\n",
        "        repo = g.get_repo(repo_name)\n",
        "\n",
        "        github_file_path = \"projeto/development/silver/orders_tratados.csv\"\n",
        "\n",
        "        try:\n",
        "            contents = repo.get_contents(github_file_path, ref=\"main\")\n",
        "            repo.update_file(\n",
        "                path=github_file_path,\n",
        "                message=f\"Atualização automática via Colab\",\n",
        "                content=df.to_csv(index=False, encoding='utf-8'),\n",
        "                sha=contents.sha,\n",
        "                branch=\"main\"\n",
        "            )\n",
        "            print(\"☁️ Arquivo atualizado no GitHub com sucesso!\")\n",
        "        except:\n",
        "            repo.create_file(\n",
        "                path=github_file_path,\n",
        "                message=f\"Criação automática ({timestamp})\",\n",
        "                content=df.to_csv(index=False, encoding='utf-8'),\n",
        "                branch=\"main\"\n",
        "            )\n",
        "            print(\"☁️ Arquivo criado no GitHub!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nErro ao enviar para o GitHub: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9rngPhjEiO9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
